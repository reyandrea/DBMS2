{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before You Start\n",
    "\n",
    "\n",
    "cd .devcontainer </br>\n",
    "run docker-compose up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.9.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.0.36)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sqlalchemy) (3.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2\n",
    "! pip install sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2  #import of the psycopg2 python library\n",
    "import pandas as pd #import of the pandas python library\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "##No transaction is started when commands are executed and no commit() or rollback() is required. \n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Successfully to PostgreSQL server!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to the postgreSQL server with username, and password credentials\n",
    "    con = psycopg2.connect(user = \"postgres\",\n",
    "                                  password = \"postgres\",\n",
    "                                  host = \"localhost\",\n",
    "                                  port = \"5432\")\n",
    "    \n",
    "    con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT);\n",
    "    print(\"Connected Successfully to PostgreSQL server!!\")\n",
    "    \n",
    "    # Obtain a DB Cursor to perform database operations\n",
    "    cursor = con.cursor();\n",
    "except (Exception, psycopg2.Error) as error :\n",
    "     print (\"Error while connecting to PostgreSQL\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that reading CSV works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   circuit_id                            name      location    country  \\\n",
      "0           1  Albert Park Grand Prix Circuit     Melbourne  Australia   \n",
      "1           2    Sepang International Circuit  Kuala Lumpur   Malaysia   \n",
      "2           3   Bahrain International Circuit        Sakhir    Bahrain   \n",
      "3           4  Circuit de Barcelona-Catalunya      Montmel처      Spain   \n",
      "4           5                   Istanbul Park      Istanbul     Turkey   \n",
      "\n",
      "        lat       long  alt                                                url  \n",
      "0 -37.84970  144.96800   10  http://en.wikipedia.org/wiki/Melbourne_Grand_P...  \n",
      "1   2.76083  101.73800   18  http://en.wikipedia.org/wiki/Sepang_Internatio...  \n",
      "2  26.03250   50.51060    7  http://en.wikipedia.org/wiki/Bahrain_Internati...  \n",
      "3  41.57000    2.26111  109  http://en.wikipedia.org/wiki/Circuit_de_Barcel...  \n",
      "4  40.95170   29.40500  130         http://en.wikipedia.org/wiki/Istanbul_Park  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('circuits.csv')\n",
    "print(df.head())  # Displays the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables created successfully in PostgreSQL \n"
     ]
    }
   ],
   "source": [
    "#Create \"test\" Table\n",
    "\n",
    "try:\n",
    "    #table_name variable\n",
    "    seasonTable=\"season\"\n",
    "    create_all_tables_query = '''\n",
    "    CREATE TABLE IF NOT EXISTS circuit (\n",
    "        circuit_id INT PRIMARY KEY,\n",
    "        -- circuit_ref omitted\n",
    "        name TEXT,\n",
    "        location TEXT,\n",
    "        country TEXT,\n",
    "        lat float,\n",
    "        long float,\n",
    "        alt INT,\n",
    "        url TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS constructor (\n",
    "        constructor_id INT PRIMARY KEY,\n",
    "        -- removing constructor_ref for normalisation purposes\n",
    "        name TEXT,\n",
    "        nationality TEXT,\n",
    "        url TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS driver (\n",
    "        driver_id INT PRIMARY KEY,\n",
    "        -- removing driver_ref and number for normalisation purposes\n",
    "        code TEXT,\n",
    "        first_name TEXT, --no longer forename\n",
    "        last_name TEXT, --no longer surname\n",
    "        dob DATE,\n",
    "        nationality TEXT,\n",
    "        url TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS lap_time (\n",
    "        race_id INT PRIMARY KEY,\n",
    "        driver_id INT REFERENCES driver,\n",
    "        lap INT,\n",
    "        position INT,\n",
    "        time_in_milliseconds INT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS pit_stop (\n",
    "        race_id INT,\n",
    "        driver_id INT,\n",
    "        PRIMARY KEY (race_id, driver_id),\n",
    "        stop INT,\n",
    "        lap INT,\n",
    "        time_in_miliseconds INT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS race (\n",
    "        race_id INT PRIMARY KEY,\n",
    "        year INT,\n",
    "        round INT,\n",
    "        circuit_id INT REFERENCES circuit,\n",
    "        name TEXT,\n",
    "        date DATE,\n",
    "        url TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS result (\n",
    "        result_id INT PRIMARY KEY,\n",
    "        race_id INT REFERENCES race,\n",
    "        driver_id INT REFERENCES driver,\n",
    "        constructor_id INT REFERENCES constructor,\n",
    "        -- number and grid omitted\n",
    "        position INT, -- use positionOrder instead of position/positionText\n",
    "        points INT,\n",
    "        laps INT,\n",
    "        -- omit time, unclean\n",
    "        time_in_miliseconds INT,\n",
    "        fastestLap INT,\n",
    "        rank INT,\n",
    "        fastest_lap_time INT,\n",
    "        fastest_lap_speed float\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS season (\n",
    "        year INT PRIMARY KEY,\n",
    "        url TEXT\n",
    "    );\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    #Execute this command (SQL Query)\n",
    "    cursor.execute(create_all_tables_query)\n",
    "    \n",
    "    # Make the changes to the database persistent\n",
    "    con.commit()\n",
    "    print(\"All tables created successfully in PostgreSQL \")\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    # if it exits with an exception the transaction is rolled back.\n",
    "    con.rollback()\n",
    "    print(\"Error While Creating the DB: \",error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('season',)\n",
      "('result',)\n",
      "('racestest',)\n",
      "('circuit',)\n",
      "('race',)\n",
      "('constructor_result',)\n",
      "('constructor',)\n",
      "('constructor_standing',)\n",
      "('driver_standing',)\n",
      "('driver',)\n",
      "('lap_time',)\n",
      "('pit_stop',)\n",
      "('result_id',)\n"
     ]
    }
   ],
   "source": [
    "# [information_schema.tables] keep listing of every table being managed by Postgres for a particular database.\n",
    "# specifying the tabel_schema to 'public' to only list tables that you create.\n",
    "cursor.execute(\"\"\"SELECT table_name \n",
    "                  FROM information_schema.tables \n",
    "                  WHERE table_schema = 'public'  \n",
    "               \"\"\")\n",
    "\n",
    "for table in cursor.fetchall():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read seasons.CSV and insert into already created tables with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# # Load the CSV file into a pandas DataFrame\n",
    "# csv_file_path = \"seasons.csv\"  # Replace with your CSV file path\n",
    "# table_name = \"season\"  # Replace with your PostgreSQL table name\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Connect to the PostgreSQL database\n",
    "# # Replace the placeholders with your database credentials\n",
    "# user = \"postgres\"\n",
    "# password = \"postgres\"\n",
    "# host = \"localhost\"\n",
    "# port = \"5432\"\n",
    "# database = \"postgres\"\n",
    "# engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# # Loop through the list of CSV files and import them into the PostgreSQL tables\n",
    "# for csv_file, table_name in csv_files:\n",
    "#     try:\n",
    "#         # Load CSV file into DataFrame\n",
    "#         df = pd.read_csv(csv_file)\n",
    "\n",
    "#         # Write the DataFrame to the PostgreSQL table\n",
    "#         df.to_sql(table_name, con=engine, if_exists=\"append\", index=False)\n",
    "#         print(f\"Data from {csv_file} successfully imported into {table_name}!\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while importing {csv_file} into {table_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CSV file into a pandas DataFrame\n",
    "# csv_file_path = \"circuits.csv\"  # Replace with your CSV file path\n",
    "# table_name = \"circuit\"  # Replace with your PostgreSQL table name\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Rename DataFrame columns to match the PostgreSQL table schema\n",
    "# df.rename(columns={\n",
    "#     \"circuitId\": \"circuit_id\",\n",
    "#     \"lng\": \"long\",\n",
    "#     # Add any other necessary mappings here\n",
    "# }, inplace=True)\n",
    "\n",
    "# # Write the DataFrame to the PostgreSQL table\n",
    "# try:\n",
    "#     df.to_sql(table_name, con=engine, if_exists=\"append\", index=False)\n",
    "#     print(f\"Data from {csv_file_path} successfully imported into {table_name}!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all CSVs and insert into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while importing circuit.csv into circuit: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"circuit_pkey\"\n",
      "DETAIL:  Key (circuit_id)=(1) already exists.\n",
      "\n",
      "[SQL: INSERT INTO circuit (circuit_id, name, location, country, lat, long, alt, url) VALUES (%(circuit_id__0)s, %(name__0)s, %(location__0)s, %(country__0)s, %(lat__0)s, %(long__0)s, %(alt__0)s, %(url__0)s), (%(circuit_id__1)s, %(name__1)s, %(location__1)s ... 9202 characters truncated ... (name__76)s, %(location__76)s, %(country__76)s, %(lat__76)s, %(long__76)s, %(alt__76)s, %(url__76)s)]\n",
      "[parameters: {'circuit_id__0': 1, 'country__0': 'Australia', 'long__0': 144.968, 'url__0': 'http://en.wikipedia.org/wiki/Melbourne_Grand_Prix_Circuit', 'name__0': 'Albert Park Grand Prix Circuit', 'alt__0': 10, 'location__0': 'Melbourne', 'lat__0': -37.8497, 'circuit_id__1': 2, 'country__1': 'Malaysia', 'long__1': 101.738, 'url__1': 'http://en.wikipedia.org/wiki/Sepang_International_Circuit', 'name__1': 'Sepang International Circuit', 'alt__1': 18, 'location__1': 'Kuala Lumpur', 'lat__1': 2.76083, 'circuit_id__2': 3, 'country__2': 'Bahrain', 'long__2': 50.5106, 'url__2': 'http://en.wikipedia.org/wiki/Bahrain_International_Circuit', 'name__2': 'Bahrain International Circuit', 'alt__2': 7, 'location__2': 'Sakhir', 'lat__2': 26.0325, 'circuit_id__3': 4, 'country__3': 'Spain', 'long__3': 2.26111, 'url__3': 'http://en.wikipedia.org/wiki/Circuit_de_Barcelona-Catalunya', 'name__3': 'Circuit de Barcelona-Catalunya', 'alt__3': 109, 'location__3': 'Montmel처', 'lat__3': 41.57, 'circuit_id__4': 5, 'country__4': 'Turkey', 'long__4': 29.405, 'url__4': 'http://en.wikipedia.org/wiki/Istanbul_Park', 'name__4': 'Istanbul Park', 'alt__4': 130, 'location__4': 'Istanbul', 'lat__4': 40.9517, 'circuit_id__5': 6, 'country__5': 'Monaco', 'long__5': 7.42056, 'url__5': 'http://en.wikipedia.org/wiki/Circuit_de_Monaco', 'name__5': 'Circuit de Monaco', 'alt__5': 7, 'location__5': 'Monte-Carlo', 'lat__5': 43.7347, 'circuit_id__6': 7, 'country__6': 'Canada' ... 516 parameters truncated ... 'location__70': 'Sochi', 'lat__70': 43.4057, 'circuit_id__71': 73, 'country__71': 'Azerbaijan', 'long__71': 49.8533, 'url__71': 'http://en.wikipedia.org/wiki/Baku_City_Circuit', 'name__71': 'Baku City Circuit', 'alt__71': -7, 'location__71': 'Baku', 'lat__71': 40.3725, 'circuit_id__72': 75, 'country__72': 'Portugal', 'long__72': -8.6267, 'url__72': 'http://en.wikipedia.org/wiki/Algarve_International_Circuit', 'name__72': 'Aut처dromo Internacional do Algarve', 'alt__72': 108, 'location__72': 'Portim찾o', 'lat__72': 37.227, 'circuit_id__73': 76, 'country__73': 'Italy', 'long__73': 11.3719, 'url__73': 'http://en.wikipedia.org/wiki/Mugello_Circuit', 'name__73': 'Autodromo Internazionale del Mugello', 'alt__73': 255, 'location__73': 'Mugello', 'lat__73': 43.9975, 'circuit_id__74': 77, 'country__74': 'Saudi Arabia', 'long__74': 39.1044, 'url__74': 'http://en.wikipedia.org/wiki/Jeddah_Street_Circuit', 'name__74': 'Jeddah Corniche Circuit', 'alt__74': 15, 'location__74': 'Jeddah', 'lat__74': 21.6319, 'circuit_id__75': 78, 'country__75': 'Qatar', 'long__75': 51.4542, 'url__75': 'http://en.wikipedia.org/wiki/Losail_International_Circuit', 'name__75': 'Losail International Circuit', 'alt__75': 12, 'location__75': 'Al Daayen', 'lat__75': 25.49, 'circuit_id__76': 79, 'country__76': 'USA', 'long__76': -80.2389, 'url__76': 'http://en.wikipedia.org/wiki/Miami_International_Autodrome', 'name__76': 'Miami International Autodrome', 'alt__76': 0, 'location__76': 'Miami', 'lat__76': 25.9581}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "An error occurred while importing constructor.csv into constructor: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"constructor_pkey\"\n",
      "DETAIL:  Key (constructor_id)=(1) already exists.\n",
      "\n",
      "[SQL: INSERT INTO constructor (constructor_id, name, nationality, url) VALUES (%(constructor_id__0)s, %(name__0)s, %(nationality__0)s, %(url__0)s), (%(constructor_id__1)s, %(name__1)s, %(nationality__1)s, %(url__1)s), (%(constructor_id__2)s, %(name__2)s, % ... 15816 characters truncated ... __210)s, %(url__210)s), (%(constructor_id__211)s, %(name__211)s, %(nationality__211)s, %(url__211)s)]\n",
      "[parameters: {'name__0': 'McLaren', 'nationality__0': 'British', 'url__0': 'http://en.wikipedia.org/wiki/McLaren', 'constructor_id__0': 1, 'name__1': 'BMW Sauber', 'nationality__1': 'German', 'url__1': 'http://en.wikipedia.org/wiki/BMW_Sauber', 'constructor_id__1': 2, 'name__2': 'Williams', 'nationality__2': 'British', 'url__2': 'http://en.wikipedia.org/wiki/Williams_Grand_Prix_Engineering', 'constructor_id__2': 3, 'name__3': 'Renault', 'nationality__3': 'French', 'url__3': 'http://en.wikipedia.org/wiki/Renault_in_Formula_One', 'constructor_id__3': 4, 'name__4': 'Toro Rosso', 'nationality__4': 'Italian', 'url__4': 'http://en.wikipedia.org/wiki/Scuderia_Toro_Rosso', 'constructor_id__4': 5, 'name__5': 'Ferrari', 'nationality__5': 'Italian', 'url__5': 'http://en.wikipedia.org/wiki/Scuderia_Ferrari', 'constructor_id__5': 6, 'name__6': 'Toyota', 'nationality__6': 'Japanese', 'url__6': 'http://en.wikipedia.org/wiki/Toyota_Racing', 'constructor_id__6': 7, 'name__7': 'Super Aguri', 'nationality__7': 'Japanese', 'url__7': 'http://en.wikipedia.org/wiki/Super_Aguri_F1', 'constructor_id__7': 8, 'name__8': 'Red Bull', 'nationality__8': 'Austrian', 'url__8': 'http://en.wikipedia.org/wiki/Red_Bull_Racing', 'constructor_id__8': 9, 'name__9': 'Force India', 'nationality__9': 'Indian', 'url__9': 'http://en.wikipedia.org/wiki/Racing_Point_Force_India', 'constructor_id__9': 10, 'name__10': 'Honda', 'nationality__10': 'Japanese', 'url__10': 'http://en.wikipedia.org/wiki/Honda_Racing_F1', 'constructor_id__10': 11, 'name__11': 'Spyker', 'nationality__11': 'Dutch', 'url__11': 'http://en.wikipedia.org/wiki/Spyker_F1', 'constructor_id__11': 12, 'name__12': 'MF1', 'nationality__12': 'Russian' ... 748 parameters truncated ... 'url__199': 'http://en.wikipedia.org/wiki/Shadow_Racing_Cars', 'constructor_id__199': 202, 'name__200': 'Shadow-Matra', 'nationality__200': 'British', 'url__200': 'http://en.wikipedia.org/wiki/Shadow_Racing_Cars', 'constructor_id__200': 203, 'name__201': 'Brabham-Alfa Romeo', 'nationality__201': 'British', 'url__201': 'http://en.wikipedia.org/wiki/Brabham', 'constructor_id__201': 204, 'name__202': 'Lotus', 'nationality__202': 'Malaysian', 'url__202': 'http://en.wikipedia.org/wiki/Lotus_Racing', 'constructor_id__202': 205, 'name__203': 'Marussia', 'nationality__203': 'Russian', 'url__203': 'http://en.wikipedia.org/wiki/Marussia_F1', 'constructor_id__203': 206, 'name__204': 'Caterham', 'nationality__204': 'Malaysian', 'url__204': 'http://en.wikipedia.org/wiki/Caterham_F1', 'constructor_id__204': 207, 'name__205': 'Lotus F1', 'nationality__205': 'British', 'url__205': 'http://en.wikipedia.org/wiki/Lotus_F1', 'constructor_id__205': 208, 'name__206': 'Manor Marussia', 'nationality__206': 'British', 'url__206': 'http://en.wikipedia.org/wiki/Manor_Motorsport', 'constructor_id__206': 209, 'name__207': 'Haas F1 Team', 'nationality__207': 'American', 'url__207': 'http://en.wikipedia.org/wiki/Haas_F1_Team', 'constructor_id__207': 210, 'name__208': 'Racing Point', 'nationality__208': 'British', 'url__208': 'http://en.wikipedia.org/wiki/Racing_Point_F1_Team', 'constructor_id__208': 211, 'name__209': 'AlphaTauri', 'nationality__209': 'Italian', 'url__209': 'http://en.wikipedia.org/wiki/Scuderia_AlphaTauri', 'constructor_id__209': 213, 'name__210': 'Alpine F1 Team', 'nationality__210': 'French', 'url__210': 'http://en.wikipedia.org/wiki/Alpine_F1_Team', 'constructor_id__210': 214, 'name__211': 'RB F1 Team', 'nationality__211': 'Italian', 'url__211': 'http://en.wikipedia.org/wiki/RB_Formula_One_Team', 'constructor_id__211': 215}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "An error occurred while importing driver.csv into driver: 'utf-8' codec can't decode byte 0xe9 in position 565: invalid continuation byte\n",
      "An error occurred while importing lap_time.csv into lap_time: (psycopg2.errors.UndefinedColumn) column \"time_in_milliseconds\" of relation \"lap_time\" does not exist\n",
      "LINE 1: ...INTO lap_time (race_id, driver_id, lap, position, time_in_mi...\n",
      "                                                             ^\n",
      "\n",
      "[SQL: INSERT INTO lap_time (race_id, driver_id, lap, position, time_in_milliseconds) VALUES (%(race_id__0)s, %(driver_id__0)s, %(lap__0)s, %(position__0)s, %(time_in_milliseconds__0)s), (%(race_id__1)s, %(driver_id__1)s, %(lap__1)s, %(position__1)s, %(time ... 103184 characters truncated ... (race_id__999)s, %(driver_id__999)s, %(lap__999)s, %(position__999)s, %(time_in_milliseconds__999)s)]\n",
      "[parameters: {'time_in_milliseconds__0': 98109, 'driver_id__0': 1, 'race_id__0': 20, 'position__0': '1:38.109', 'lap__0': 1, 'time_in_milliseconds__1': 93006, 'driver_id__1': 2, 'race_id__1': 20, 'position__1': '1:33.006', 'lap__1': 1, 'time_in_milliseconds__2': 92713, 'driver_id__2': 3, 'race_id__2': 20, 'position__2': '1:32.713', 'lap__2': 1, 'time_in_milliseconds__3': 92803, 'driver_id__3': 4, 'race_id__3': 20, 'position__3': '1:32.803', 'lap__3': 1, 'time_in_milliseconds__4': 92342, 'driver_id__4': 5, 'race_id__4': 20, 'position__4': '1:32.342', 'lap__4': 1, 'time_in_milliseconds__5': 92605, 'driver_id__5': 6, 'race_id__5': 20, 'position__5': '1:32.605', 'lap__5': 1, 'time_in_milliseconds__6': 92502, 'driver_id__6': 7, 'race_id__6': 20, 'position__6': '1:32.502', 'lap__6': 1, 'time_in_milliseconds__7': 92537, 'driver_id__7': 8, 'race_id__7': 20, 'position__7': '1:32.537', 'lap__7': 1, 'time_in_milliseconds__8': 93240, 'driver_id__8': 9, 'race_id__8': 20, 'position__8': '1:33.240', 'lap__8': 1, 'time_in_milliseconds__9': 92572, 'driver_id__9': 10, 'race_id__9': 20, 'position__9': '1:32.572', 'lap__9': 1 ... 4900 parameters truncated ... 'time_in_milliseconds__990': 92297, 'driver_id__990': 32, 'race_id__990': 22, 'position__990': '1:32.297', 'lap__990': 15, 'time_in_milliseconds__991': 92553, 'driver_id__991': 33, 'race_id__991': 22, 'position__991': '1:32.553', 'lap__991': 15, 'time_in_milliseconds__992': 92206, 'driver_id__992': 34, 'race_id__992': 22, 'position__992': '1:32.206', 'lap__992': 15, 'time_in_milliseconds__993': 92279, 'driver_id__993': 35, 'race_id__993': 22, 'position__993': '1:32.279', 'lap__993': 15, 'time_in_milliseconds__994': 95167, 'driver_id__994': 36, 'race_id__994': 22, 'position__994': '1:35.167', 'lap__994': 15, 'time_in_milliseconds__995': 93247, 'driver_id__995': 37, 'race_id__995': 22, 'position__995': '1:33.247', 'lap__995': 15, 'time_in_milliseconds__996': 92676, 'driver_id__996': 38, 'race_id__996': 22, 'position__996': '1:32.676', 'lap__996': 15, 'time_in_milliseconds__997': 92876, 'driver_id__997': 39, 'race_id__997': 22, 'position__997': '1:32.876', 'lap__997': 15, 'time_in_milliseconds__998': 115064, 'driver_id__998': 40, 'race_id__998': 22, 'position__998': '1:55.064', 'lap__998': 15, 'time_in_milliseconds__999': 103533, 'driver_id__999': 41, 'race_id__999': 22, 'position__999': '1:43.533', 'lap__999': 15}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "An error occurred while importing pit_stop.csv into pit_stop: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"pit_stop_pkey\"\n",
      "DETAIL:  Key (race_id, driver_id)=(841, 153) already exists.\n",
      "\n",
      "[SQL: INSERT INTO pit_stop (race_id, driver_id, stop, lap, time_in_miliseconds) VALUES (%(race_id__0)s, %(driver_id__0)s, %(stop__0)s, %(lap__0)s, %(time_in_miliseconds__0)s), (%(race_id__1)s, %(driver_id__1)s, %(stop__1)s, %(lap__1)s, %(time_in_milisecond ... 98179 characters truncated ... ), (%(race_id__999)s, %(driver_id__999)s, %(stop__999)s, %(lap__999)s, %(time_in_miliseconds__999)s)]\n",
      "[parameters: {'time_in_miliseconds__0': 26898, 'driver_id__0': 153, 'race_id__0': 841, 'stop__0': 1, 'lap__0': 1, 'time_in_miliseconds__1': 25021, 'driver_id__1': 30, 'race_id__1': 841, 'stop__1': 1, 'lap__1': 1, 'time_in_miliseconds__2': 23426, 'driver_id__2': 17, 'race_id__2': 841, 'stop__2': 1, 'lap__2': 11, 'time_in_miliseconds__3': 23251, 'driver_id__3': 4, 'race_id__3': 841, 'stop__3': 1, 'lap__3': 12, 'time_in_miliseconds__4': 23842, 'driver_id__4': 13, 'race_id__4': 841, 'stop__4': 1, 'lap__4': 13, 'time_in_miliseconds__5': 23643, 'driver_id__5': 22, 'race_id__5': 841, 'stop__5': 1, 'lap__5': 13, 'time_in_miliseconds__6': 22603, 'driver_id__6': 20, 'race_id__6': 841, 'stop__6': 1, 'lap__6': 14, 'time_in_miliseconds__7': 24863, 'driver_id__7': 814, 'race_id__7': 841, 'stop__7': 1, 'lap__7': 14, 'time_in_miliseconds__8': 25259, 'driver_id__8': 816, 'race_id__8': 841, 'stop__8': 1, 'lap__8': 14, 'time_in_miliseconds__9': 25342, 'driver_id__9': 67, 'race_id__9': 841, 'stop__9': 1, 'lap__9': 15 ... 4900 parameters truncated ... 'time_in_miliseconds__990': 25074, 'driver_id__990': 817, 'race_id__990': 857, 'stop__990': 1, 'lap__990': 25, 'time_in_miliseconds__991': 22894, 'driver_id__991': 15, 'race_id__991': 857, 'stop__991': 2, 'lap__991': 27, 'time_in_miliseconds__992': 14919, 'driver_id__992': 13, 'race_id__992': 857, 'stop__992': 2, 'lap__992': 30, 'time_in_miliseconds__993': 27619, 'driver_id__993': 13, 'race_id__993': 857, 'stop__993': 3, 'lap__993': 31, 'time_in_miliseconds__994': 42529, 'driver_id__994': 817, 'race_id__994': 857, 'stop__994': 2, 'lap__994': 32, 'time_in_miliseconds__995': 22519, 'driver_id__995': 808, 'race_id__995': 857, 'stop__995': 2, 'lap__995': 33, 'time_in_miliseconds__996': 24789, 'driver_id__996': 815, 'race_id__996': 857, 'stop__996': 2, 'lap__996': 34, 'time_in_miliseconds__997': 21977, 'driver_id__997': 16, 'race_id__997': 857, 'stop__997': 2, 'lap__997': 35, 'time_in_miliseconds__998': 22339, 'driver_id__998': 22, 'race_id__998': 857, 'stop__998': 2, 'lap__998': 35, 'time_in_miliseconds__999': 21240, 'driver_id__999': 17, 'race_id__999': 857, 'stop__999': 2, 'lap__999': 37}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "An error occurred while importing race.csv into race: (psycopg2.errors.DatetimeFieldOverflow) date/time field value out of range: \"29/3/2009\"\n",
      "LINE 1: ...) VALUES (1, 2009, 1, 1, 'Australian Grand Prix', '29/3/2009...\n",
      "                                                             ^\n",
      "HINT:  Perhaps you need a different \"datestyle\" setting.\n",
      "\n",
      "[SQL: INSERT INTO race (race_id, year, round, circuit_id, name, date, url) VALUES (%(race_id__0)s, %(year__0)s, %(round__0)s, %(circuit_id__0)s, %(name__0)s, %(date__0)s, %(url__0)s), (%(race_id__1)s, %(year__1)s, %(round__1)s, %(circuit_id__1)s, %(name__1 ... 114954 characters truncated ... 9)s, %(year__999)s, %(round__999)s, %(circuit_id__999)s, %(name__999)s, %(date__999)s, %(url__999)s)]\n",
      "[parameters: {'circuit_id__0': 1, 'url__0': 'http://en.wikipedia.org/wiki/2009_Australian_Grand_Prix', 'date__0': '29/3/2009', 'round__0': 1, 'year__0': 2009, 'race_id__0': 1, 'name__0': 'Australian Grand Prix', 'circuit_id__1': 2, 'url__1': 'http://en.wikipedia.org/wiki/2009_Malaysian_Grand_Prix', 'date__1': '5/4/2009', 'round__1': 2, 'year__1': 2009, 'race_id__1': 2, 'name__1': 'Malaysian Grand Prix', 'circuit_id__2': 17, 'url__2': 'http://en.wikipedia.org/wiki/2009_Chinese_Grand_Prix', 'date__2': '19/4/2009', 'round__2': 3, 'year__2': 2009, 'race_id__2': 3, 'name__2': 'Chinese Grand Prix', 'circuit_id__3': 3, 'url__3': 'http://en.wikipedia.org/wiki/2009_Bahrain_Grand_Prix', 'date__3': '26/4/2009', 'round__3': 4, 'year__3': 2009, 'race_id__3': 4, 'name__3': 'Bahrain Grand Prix', 'circuit_id__4': 4, 'url__4': 'http://en.wikipedia.org/wiki/2009_Spanish_Grand_Prix', 'date__4': '10/5/2009', 'round__4': 5, 'year__4': 2009, 'race_id__4': 5, 'name__4': 'Spanish Grand Prix', 'circuit_id__5': 6, 'url__5': 'http://en.wikipedia.org/wiki/2009_Monaco_Grand_Prix', 'date__5': '24/5/2009', 'round__5': 6, 'year__5': 2009, 'race_id__5': 6, 'name__5': 'Monaco Grand Prix', 'circuit_id__6': 5, 'url__6': 'http://en.wikipedia.org/wiki/2009_Turkish_Grand_Prix', 'date__6': '7/6/2009', 'round__6': 7, 'year__6': 2009, 'race_id__6': 7, 'name__6': 'Turkish Grand Prix', 'circuit_id__7': 9 ... 6900 parameters truncated ... 'name__992': 'Japanese Grand Prix', 'circuit_id__993': 69, 'url__993': 'http://en.wikipedia.org/wiki/2018_United_States_Grand_Prix', 'date__993': '21/10/2018', 'round__993': 18, 'year__993': 2018, 'race_id__993': 1006, 'name__993': 'United States Grand Prix', 'circuit_id__994': 32, 'url__994': 'http://en.wikipedia.org/wiki/2018_Mexican_Grand_Prix', 'date__994': '28/10/2018', 'round__994': 19, 'year__994': 2018, 'race_id__994': 1007, 'name__994': 'Mexican Grand Prix', 'circuit_id__995': 18, 'url__995': 'http://en.wikipedia.org/wiki/2018_Brazilian_Grand_Prix', 'date__995': '11/11/2018', 'round__995': 20, 'year__995': 2018, 'race_id__995': 1008, 'name__995': 'Brazilian Grand Prix', 'circuit_id__996': 24, 'url__996': 'http://en.wikipedia.org/wiki/2018_Abu_Dhabi_Grand_Prix', 'date__996': '25/11/2018', 'round__996': 21, 'year__996': 2018, 'race_id__996': 1009, 'name__996': 'Abu Dhabi Grand Prix', 'circuit_id__997': 1, 'url__997': 'http://en.wikipedia.org/wiki/2019_Australian_Grand_Prix', 'date__997': '17/3/2019', 'round__997': 1, 'year__997': 2019, 'race_id__997': 1010, 'name__997': 'Australian Grand Prix', 'circuit_id__998': 3, 'url__998': 'http://en.wikipedia.org/wiki/2019_Bahrain_Grand_Prix', 'date__998': '31/3/2019', 'round__998': 2, 'year__998': 2019, 'race_id__998': 1011, 'name__998': 'Bahrain Grand Prix', 'circuit_id__999': 17, 'url__999': 'http://en.wikipedia.org/wiki/2019_Chinese_Grand_Prix', 'date__999': '14/4/2019', 'round__999': 3, 'year__999': 2019, 'race_id__999': 1012, 'name__999': 'Chinese Grand Prix'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/9h9h)\n",
      "An error occurred while importing result.csv into result: (psycopg2.errors.UndefinedColumn) column \"race_id.1\" of relation \"result\" does not exist\n",
      "LINE 1: INSERT INTO result (result_id, race_id, \"race_id.1\", constru...\n",
      "                                                ^\n",
      "\n",
      "[SQL: INSERT INTO result (result_id, race_id, \"race_id.1\", constructor_id, position, points, laps, time_in_miliseconds, \"fastestLap\", rank, fastest_lap_time, fastest_lap_speed) VALUES (%(result_id__0)s, %(race_id__0)s, %(race_id_1__0)s, %(constructor_id__0 ... 255506 characters truncated ... s__999)s, %(fastestLap__999)s, %(rank__999)s, %(fastest_lap_time__999)s, %(fastest_lap_speed__999)s)]\n",
      "[parameters: {'time_in_miliseconds__0': '5690616', 'fastest_lap_time__0': '01:27.5', 'laps__0': 58, 'fastest_lap_speed__0': '218.3', 'race_id_1__0': 1, 'points__0': 10.0, 'result_id__0': 1, 'fastestLap__0': '39', 'race_id__0': 18, 'position__0': 1, 'rank__0': '2', 'constructor_id__0': 1, 'time_in_miliseconds__1': '5696094', 'fastest_lap_time__1': '01:27.7', 'laps__1': 58, 'fastest_lap_speed__1': '217.586', 'race_id_1__1': 2, 'points__1': 8.0, 'result_id__1': 2, 'fastestLap__1': '41', 'race_id__1': 18, 'position__1': 2, 'rank__1': '3', 'constructor_id__1': 2, 'time_in_miliseconds__2': '5698779', 'fastest_lap_time__2': '01:28.1', 'laps__2': 58, 'fastest_lap_speed__2': '216.719', 'race_id_1__2': 3, 'points__2': 6.0, 'result_id__2': 3, 'fastestLap__2': '41', 'race_id__2': 18, 'position__2': 3, 'rank__2': '5', 'constructor_id__2': 3, 'time_in_miliseconds__3': '5707797', 'fastest_lap_time__3': '01:28.6', 'laps__3': 58, 'fastest_lap_speed__3': '215.464', 'race_id_1__3': 4, 'points__3': 5.0, 'result_id__3': 4, 'fastestLap__3': '58', 'race_id__3': 18, 'position__3': 4, 'rank__3': '7', 'constructor_id__3': 4, 'time_in_miliseconds__4': '5708630', 'fastest_lap_time__4': '01:27.4' ... 11900 parameters truncated ... 'rank__995': '11', 'constructor_id__995': 5, 'time_in_miliseconds__996': '\\\\N', 'fastest_lap_time__996': '01:16.8', 'laps__996': 59, 'fastest_lap_speed__996': '214.372', 'race_id_1__996': 17, 'points__996': 0.0, 'result_id__996': 997, 'fastestLap__996': '43', 'race_id__996': 64, 'position__996': 13, 'rank__996': '6', 'constructor_id__996': 3, 'time_in_miliseconds__997': '\\\\N', 'fastest_lap_time__997': '01:19.4', 'laps__997': 38, 'fastest_lap_speed__997': '207.351', 'race_id_1__997': 11, 'points__997': 0.0, 'result_id__997': 998, 'fastestLap__997': '26', 'race_id__997': 64, 'position__997': 14, 'rank__997': '19', 'constructor_id__997': 8, 'time_in_miliseconds__998': '\\\\N', 'fastest_lap_time__998': '01:18.9', 'laps__998': 30, 'fastest_lap_speed__998': '208.689', 'race_id_1__998': 35, 'points__998': 0.0, 'result_id__998': 999, 'fastestLap__998': '29', 'race_id__998': 64, 'position__998': 15, 'rank__998': '17', 'constructor_id__998': 2, 'time_in_miliseconds__999': '\\\\N', 'fastest_lap_time__999': '01:18.0', 'laps__999': 18, 'fastest_lap_speed__999': '211.029', 'race_id_1__999': 22, 'points__999': 0.0, 'result_id__999': 1000, 'fastestLap__999': '16', 'race_id__999': 64, 'position__999': 16, 'rank__999': '14', 'constructor_id__999': 11}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "An error occurred while importing season.csv into season: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"season_pkey\"\n",
      "DETAIL:  Key (year)=(2009) already exists.\n",
      "\n",
      "[SQL: INSERT INTO season (year, url) VALUES (%(year__0)s, %(url__0)s), (%(year__1)s, %(url__1)s), (%(year__2)s, %(url__2)s), (%(year__3)s, %(url__3)s), (%(year__4)s, %(url__4)s), (%(year__5)s, %(url__5)s), (%(year__6)s, %(url__6)s), (%(year__7)s, %(url__7) ... 1841 characters truncated ...  %(url__71)s), (%(year__72)s, %(url__72)s), (%(year__73)s, %(url__73)s), (%(year__74)s, %(url__74)s)]\n",
      "[parameters: {'year__0': 2009, 'url__0': 'http://en.wikipedia.org/wiki/2009_Formula_One_season', 'year__1': 2008, 'url__1': 'http://en.wikipedia.org/wiki/2008_Formula_One_season', 'year__2': 2007, 'url__2': 'http://en.wikipedia.org/wiki/2007_Formula_One_season', 'year__3': 2006, 'url__3': 'http://en.wikipedia.org/wiki/2006_Formula_One_season', 'year__4': 2005, 'url__4': 'http://en.wikipedia.org/wiki/2005_Formula_One_season', 'year__5': 2004, 'url__5': 'http://en.wikipedia.org/wiki/2004_Formula_One_season', 'year__6': 2003, 'url__6': 'http://en.wikipedia.org/wiki/2003_Formula_One_season', 'year__7': 2002, 'url__7': 'http://en.wikipedia.org/wiki/2002_Formula_One_season', 'year__8': 2001, 'url__8': 'http://en.wikipedia.org/wiki/2001_Formula_One_season', 'year__9': 2000, 'url__9': 'http://en.wikipedia.org/wiki/2000_Formula_One_season', 'year__10': 1999, 'url__10': 'http://en.wikipedia.org/wiki/1999_Formula_One_season', 'year__11': 1998, 'url__11': 'http://en.wikipedia.org/wiki/1998_Formula_One_season', 'year__12': 1997, 'url__12': 'http://en.wikipedia.org/wiki/1997_Formula_One_season', 'year__13': 1996, 'url__13': 'http://en.wikipedia.org/wiki/1996_Formula_One_season', 'year__14': 1995, 'url__14': 'http://en.wikipedia.org/wiki/1995_Formula_One_season', 'year__15': 1994, 'url__15': 'http://en.wikipedia.org/wiki/1994_Formula_One_season', 'year__16': 1993, 'url__16': 'http://en.wikipedia.org/wiki/1993_Formula_One_season', 'year__17': 1992, 'url__17': 'http://en.wikipedia.org/wiki/1992_Formula_One_season', 'year__18': 1991, 'url__18': 'http://en.wikipedia.org/wiki/1991_Formula_One_season', 'year__19': 1990, 'url__19': 'http://en.wikipedia.org/wiki/1990_Formula_One_season', 'year__20': 2010, 'url__20': 'http://en.wikipedia.org/wiki/2010_Formula_One_season', 'year__21': 1989, 'url__21': 'http://en.wikipedia.org/wiki/1989_Formula_One_season', 'year__22': 1988, 'url__22': 'http://en.wikipedia.org/wiki/1988_Formula_One_season', 'year__23': 1987, 'url__23': 'http://en.wikipedia.org/wiki/1987_Formula_One_season', 'year__24': 1986, 'url__24': 'http://en.wikipedia.org/wiki/1986_Formula_One_season' ... 50 parameters truncated ... 'year__50': 1960, 'url__50': 'http://en.wikipedia.org/wiki/1960_Formula_One_season', 'year__51': 1959, 'url__51': 'http://en.wikipedia.org/wiki/1959_Formula_One_season', 'year__52': 1958, 'url__52': 'http://en.wikipedia.org/wiki/1958_Formula_One_season', 'year__53': 1957, 'url__53': 'http://en.wikipedia.org/wiki/1957_Formula_One_season', 'year__54': 1956, 'url__54': 'http://en.wikipedia.org/wiki/1956_Formula_One_season', 'year__55': 1955, 'url__55': 'http://en.wikipedia.org/wiki/1955_Formula_One_season', 'year__56': 1954, 'url__56': 'http://en.wikipedia.org/wiki/1954_Formula_One_season', 'year__57': 1953, 'url__57': 'http://en.wikipedia.org/wiki/1953_Formula_One_season', 'year__58': 1952, 'url__58': 'http://en.wikipedia.org/wiki/1952_Formula_One_season', 'year__59': 1951, 'url__59': 'http://en.wikipedia.org/wiki/1951_Formula_One_season', 'year__60': 1950, 'url__60': 'http://en.wikipedia.org/wiki/1950_Formula_One_season', 'year__61': 2011, 'url__61': 'http://en.wikipedia.org/wiki/2011_Formula_One_season', 'year__62': 2012, 'url__62': 'http://en.wikipedia.org/wiki/2012_Formula_One_season', 'year__63': 2013, 'url__63': 'http://en.wikipedia.org/wiki/2013_Formula_One_season', 'year__64': 2014, 'url__64': 'http://en.wikipedia.org/wiki/2014_Formula_One_season', 'year__65': 2015, 'url__65': 'http://en.wikipedia.org/wiki/2015_Formula_One_season', 'year__66': 2016, 'url__66': 'http://en.wikipedia.org/wiki/2016_Formula_One_season', 'year__67': 2017, 'url__67': 'http://en.wikipedia.org/wiki/2017_Formula_One_season', 'year__68': 2018, 'url__68': 'http://en.wikipedia.org/wiki/2018_Formula_One_World_Championship', 'year__69': 2019, 'url__69': 'http://en.wikipedia.org/wiki/2019_Formula_One_World_Championship', 'year__70': 2020, 'url__70': 'http://en.wikipedia.org/wiki/2020_Formula_One_World_Championship', 'year__71': 2021, 'url__71': 'http://en.wikipedia.org/wiki/2021_Formula_One_World_Championship', 'year__72': 2022, 'url__72': 'http://en.wikipedia.org/wiki/2022_Formula_One_World_Championship', 'year__73': 2023, 'url__73': 'http://en.wikipedia.org/wiki/2023_Formula_One_World_Championship', 'year__74': 2024, 'url__74': 'https://en.wikipedia.org/wiki/2024_Formula_One_World_Championship'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# List of CSV files and corresponding table names\n",
    "csv_files = [\n",
    "    (\"circuit.csv\", \"circuit\"),\n",
    "    (\"constructor.csv\", \"constructor\"),\n",
    "    (\"driver.csv\", \"driver\"),\n",
    "    (\"lap_time.csv\", \"lap_time\"),\n",
    "    (\"pit_stop.csv\", \"pit_stop\"),\n",
    "    (\"race.csv\", \"race\"),\n",
    "    (\"result.csv\", \"result\"),\n",
    "    (\"season.csv\", \"season\")\n",
    "]\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "user = \"postgres\"\n",
    "password = \"postgres\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"postgres\"\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# Loop through the list of CSV files and import them into the PostgreSQL tables\n",
    "for csv_file, table_name in csv_files:\n",
    "    try:\n",
    "        # Load CSV file into DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Write the DataFrame to the PostgreSQL table\n",
    "        df.to_sql(table_name, con=engine, if_exists=\"append\", index=False)\n",
    "        print(f\"Data from {csv_file} successfully imported into {table_name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while importing {csv_file} into {table_name}: {e}\")\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# # Load the CSV file into a pandas DataFrame\n",
    "# csv_file_path = \"races.csv\"  # Replace with your CSV file path\n",
    "# table_name = \"race\"  # Replace with your PostgreSQL table name\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Rename DataFrame columns to match the PostgreSQL table schema\n",
    "# df.rename(columns={\n",
    "#     \"raceId\": \"race_id\",\n",
    "#     \"circuitId\": \"circuit_id\",\n",
    "#     # Add any other necessary mappings here\n",
    "# }, inplace=True)\n",
    "\n",
    "# columns_to_keep = [\"race_id\", \"year\", \"round\", \"circuit_id\", \"name\", \"date\", \"url\"]\n",
    "# df = df[columns_to_keep]\n",
    "\n",
    "# # Connect to the PostgreSQL database\n",
    "# # Replace the placeholders with your database credentials\n",
    "# user = \"postgres\"\n",
    "# password = \"postgres\"\n",
    "# host = \"localhost\"\n",
    "# port = \"5432\"\n",
    "# database = \"postgres\"\n",
    "# engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# # Write the DataFrame to the PostgreSQL table\n",
    "# try:\n",
    "#     df.to_sql(table_name, con=engine, if_exists=\"append\", index=False)\n",
    "#     print(f\"Data from {csv_file_path} successfully imported into {table_name}!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c272c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c272c_level0_col0\" class=\"col_heading level0 col0\" >race_id</th>\n",
       "      <th id=\"T_c272c_level0_col1\" class=\"col_heading level0 col1\" >year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c272c_row0_col0\" class=\"data row0 col0\" >141</td>\n",
       "      <td id=\"T_c272c_row0_col1\" class=\"data row0 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c272c_row1_col0\" class=\"data row1 col0\" >142</td>\n",
       "      <td id=\"T_c272c_row1_col1\" class=\"data row1 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c272c_row2_col0\" class=\"data row2 col0\" >143</td>\n",
       "      <td id=\"T_c272c_row2_col1\" class=\"data row2 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c272c_row3_col0\" class=\"data row3 col0\" >144</td>\n",
       "      <td id=\"T_c272c_row3_col1\" class=\"data row3 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c272c_row4_col0\" class=\"data row4 col0\" >145</td>\n",
       "      <td id=\"T_c272c_row4_col1\" class=\"data row4 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c272c_row5_col0\" class=\"data row5 col0\" >146</td>\n",
       "      <td id=\"T_c272c_row5_col1\" class=\"data row5 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c272c_row6_col0\" class=\"data row6 col0\" >147</td>\n",
       "      <td id=\"T_c272c_row6_col1\" class=\"data row6 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c272c_row7_col0\" class=\"data row7 col0\" >148</td>\n",
       "      <td id=\"T_c272c_row7_col1\" class=\"data row7 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c272c_row8_col0\" class=\"data row8 col0\" >149</td>\n",
       "      <td id=\"T_c272c_row8_col1\" class=\"data row8 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c272c_row9_col0\" class=\"data row9 col0\" >150</td>\n",
       "      <td id=\"T_c272c_row9_col1\" class=\"data row9 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c272c_row10_col0\" class=\"data row10 col0\" >151</td>\n",
       "      <td id=\"T_c272c_row10_col1\" class=\"data row10 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c272c_row11_col0\" class=\"data row11 col0\" >152</td>\n",
       "      <td id=\"T_c272c_row11_col1\" class=\"data row11 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c272c_row12_col0\" class=\"data row12 col0\" >153</td>\n",
       "      <td id=\"T_c272c_row12_col1\" class=\"data row12 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c272c_row13_col0\" class=\"data row13 col0\" >154</td>\n",
       "      <td id=\"T_c272c_row13_col1\" class=\"data row13 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c272c_row14_col0\" class=\"data row14 col0\" >155</td>\n",
       "      <td id=\"T_c272c_row14_col1\" class=\"data row14 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c272c_row15_col0\" class=\"data row15 col0\" >156</td>\n",
       "      <td id=\"T_c272c_row15_col1\" class=\"data row15 col1\" >2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c272c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c272c_row16_col0\" class=\"data row16 col0\" >157</td>\n",
       "      <td id=\"T_c272c_row16_col1\" class=\"data row16 col1\" >2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x720fdc41fc20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sql_select_query = \"\"\" SELECT * FROM season WHERE year = 2001\"\"\"\n",
    "# sql_select_query = \"\"\" SELECT r.race_id, r.year FROM race as r JOIN season as s ON s.year = r.year WHERE s.year = 2001\"\"\"\n",
    "\n",
    "# try:\n",
    "#     cursor.execute(sql_select_query, (1,))\n",
    "#     person_records = cursor.fetchall() \n",
    "#     print(\"Print each row and it's columns values:\\n\")\n",
    "#     # print(person_records)\n",
    "#     df = pd.DataFrame(person_records, columns=['race_id', 'year'])\n",
    "#     print(df)\n",
    "# except(Exception, psycopg2.Error) as error :\n",
    "#     con.rollback()\n",
    "#     print(\"Error:\", error)\n",
    "\n",
    "\n",
    "Countries_Customers_Cnt_gt1= psql.read_sql(\"\"\"SELECT r.race_id, r.year \n",
    "                                           FROM race as r \n",
    "                                           JOIN season as s \n",
    "                                           ON s.year = r.year \n",
    "                                           WHERE s.year = 2001\n",
    "                                          \"\"\", engine)\n",
    "display(Countries_Customers_Cnt_gt1.style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
